{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSmr2d3NfjTe5zXuKSp3OX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coletted1/Model-Theft-Project/blob/main/ModelTheftProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Extraction Attack"
      ],
      "metadata": {
        "id": "vpBTdfCTTe4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Victim Model Description\n",
        "\n",
        "**Purpose of the Model:**\n",
        "\n",
        "The victim model is a neural network designed for the classification of handwritten digits, I chose this as it is a common task in image processing and computer vision. Real-word uses of digit classification include postal code sorting for mail, bank check processing, and educational tools such as Photomath.\n",
        "\n",
        "**Description of Training Data:**\n",
        "\n",
        "The model was trained on the MNIST dataset, which consists of 60,000 training images and 10,000 test images of handwritten digits, each being a 28x28 pixel grayscale image.\n",
        "\n",
        "**Model Architecture and Hyperparameters:**\n",
        "\n",
        "*   **Architecture:** Sequential neural network model with two dense layers\n",
        "*   **Layers:**\n",
        " * A Flatten layer to transform the input images (28x28 pixels) into a 1D array\n",
        " * A Dense layer with 128 neurons, using the ReLU (Rectified Linear Unit) activation function. This layer is responsible for learning features from the flattened input\n",
        " * A Dense output layer with 10 neurons (corresponding to the 10 digit classes of MNIST), using the Softmax activation function for multi-class classification\n",
        "\n",
        "*   **Hyperparameters:**\n",
        " *    Optimizer: Adam, a popular optimizer that adapts the learning rate during training\n",
        " *    Loss function: Categorical Crossentropy, suitable for the multi-class classification problem\n",
        " *    Training Epochs: The model is trained for 5 epochs\n",
        "\n",
        "**Model Metrics:**\n",
        "\n",
        "* Accuracy: Achieved an accuracy of 98.62% on the training dataset.\n",
        "* Precision: Reflects the model's ability to correctly identify only relevant instances (true positives)\n",
        "* Recall: Indicates the model's ability to find all relevant instances (true positives) in the dataset\n",
        "* F1 Score: A mean of precision and recall, providing a balance between them"
      ],
      "metadata": {
        "id": "s-lgdwgFRReF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Extraction Attack Technique\n",
        "\n",
        "**Summary of Technique:**\n",
        "\n",
        "The chosen technique for the attack was Substitute Model Training. This involved querying the victim model with a subset of the MNIST test dataset and using the predictions to train a substitute model.\n",
        "\n",
        "**Pros and Cons:**\n",
        "\n",
        "*    Pros:\n",
        " * Does not require knowledge of the victim model’s internal architecture\n",
        " * Can be effective even with limited data\n",
        "\n",
        "*    Cons:\n",
        " * The quality of the substitute model depends on the representativeness of the query dataset\n",
        " * Requires multiple queries to the victim model, which could be detected\n",
        "\n",
        " **Resources Required:**\n",
        "\n",
        "* A dataset to query the victim model\n",
        "* Computational resources for training the substitute model\n",
        "* Time and understanding of machine learning for implementing and tuning the model\n"
      ],
      "metadata": {
        "id": "lti3dbVWZYbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Discussion of Results\n",
        "\n",
        "**Comparison of Extracted Model to Victim Model:**\n",
        "\n",
        "* **Victim Model:** The victim model, built with a sequential architecture comprising two dense layers, demonstrated robust performance metrics. By the final epoch of training, it achieved an accuracy of 98.55%, precision of 98.74%, recall of 98.39%, and an F1 score of 98.53%. These results indicate a high degree of reliability in classifying the MNIST dataset, with balanced precision and recall.\n",
        "* **Substitute Model:** The substitute model, with a different architecture (64-neuron layer instead of 128), displayed progressive improvement over its training epochs, achieving an accuracy of 92.20% by the final epoch. When evaluated on the original test set, the model reached an accuracy of 86.64%.\n",
        "* **Comparative Analysis:** There is a noticeable difference in the performance of the substitute model compared to the victim model. The substitute model's accuracy is lower (86.64% vs. 98.55%). This gap could be attributed to differences in architecture, the quality of data labeled by the victim model for training the substitute, or limitations inherent to the model extraction process. The accuracy of the substitute model on the test dataset (86.64%) is a crucial metric. It's lower than the victim model's accuracy, suggesting the extracted model has not completely replicated the victim model’s high level of performance.\n"
      ],
      "metadata": {
        "id": "5rGuRCW-crY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D. Code\n",
        "### Train Victim Model"
      ],
      "metadata": {
        "id": "DCuPgu6QEBBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXAZu7azzl61",
        "outputId": "01b51a98-2dca-49bf-f643-876f3d06e99b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/611.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m512.0/611.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import statenements\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalizes the training/testing images by scaling the pixel values to be between 0 and 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# Build and compile the victim model\n",
        "victim_model = Sequential([ # Initializes a new sequential model\n",
        "    Flatten(input_shape=(28, 28)), # Adds a flatten layer to the model that flattens the 28x28 input images to a 1D array\n",
        "    Dense(128, activation='relu'), # Adds a dense layer with 128 neurons and ReLU (Rectified Linear Unit) activation function\n",
        "    Dense(10, activation='softmax') # Adds a dense layer with 10 neurons (one for each digit) and a softmax activation function\n",
        "])\n",
        "victim_model.compile(optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy', Precision(), Recall(), tfa.metrics.F1Score(num_classes=10, average='macro')])\n",
        "\n",
        "\n",
        "# Train the victim model\n",
        "victim_model.fit(train_images, train_labels, epochs=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2gb4LpUDqLO",
        "outputId": "02555050-5c74-4945-a28b-a090e8070715"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 17s 8ms/step - loss: 0.2659 - accuracy: 0.9237 - precision_11: 0.9523 - recall_6: 0.8955 - f1_score: 0.9229\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1161 - accuracy: 0.9658 - precision_11: 0.9722 - recall_6: 0.9601 - f1_score: 0.9655\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0794 - accuracy: 0.9762 - precision_11: 0.9803 - recall_6: 0.9726 - f1_score: 0.9760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0600 - accuracy: 0.9816 - precision_11: 0.9840 - recall_6: 0.9796 - f1_score: 0.9815\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0458 - accuracy: 0.9855 - precision_11: 0.9874 - recall_6: 0.9839 - f1_score: 0.9853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f7d47e5a800>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query the Victim Model to Label a New Dataset"
      ],
      "metadata": {
        "id": "pKjnWzgCEvUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate new set of images\n",
        "query_images = test_images[:1000]  # 1000 images from the test set\n",
        "\n",
        "# Use the victim model to label these images\n",
        "query_labels = np.argmax(victim_model.predict(query_images), axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UjCQnkgEzYe",
        "outputId": "5ae96c7a-b62b-4496-89db-a3527b33afa4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Substitute Model on the Queried Data"
      ],
      "metadata": {
        "id": "Ss2x2F56E2gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the substitute model\n",
        "substitute_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(64, activation='relu'),  # Different architecture\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "substitute_model.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# Train the substitute model on the queried data\n",
        "substitute_model.fit(query_images, query_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TNY5v0AE6cN",
        "outputId": "65d4d8f8-0341-4a48-a88a-fe40c49bd267"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 1.7644 - accuracy: 0.5250\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.8090\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.8640\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.9020\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.9180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f7d3f84f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the Substitute Model"
      ],
      "metadata": {
        "id": "EloJuNG0E8oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test labels from one-hot encoding to sparse format\n",
        "sparse_test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Evaluate the substitute model on the original test set with sparse labels\n",
        "substitute_model.evaluate(test_images, sparse_test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM40BoRPFAhn",
        "outputId": "0f4f5029-d8dc-4f74-b721-7070e16c7046"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47845184803009033, 0.859499990940094]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}